# Ollama

- **Category:** AI Integration
- **Version:** Latest
- **Website/Docs:** https://ollama.com/
- **Why Chosen:** Local LLM runner, easy to use, supports multiple models.
- **Key Features:** Runs LLMs locally, REST API, model management.
- **Integration Points:** Backend agent orchestrator, FastAPI.
- **Alternatives Considered:** llama.cpp, text-generation-webui, OpenAI API
- **Risks/Limitations:** Not open source, limited to supported models.
- **Best Practices:** Keep models updated, monitor resource usage.
